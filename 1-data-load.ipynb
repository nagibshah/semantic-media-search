{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358df75c-bca4-4c40-a935-481e91c23fb1",
   "metadata": {},
   "source": [
    "# Multi Modal Semantic Search Data Preparation \n",
    "\n",
    "This notebook is used to download, curate/fabricate some media assets required to complete the workshop. In order to achieve sufficient variance within the dataset as well as similar media assets we will be combining some real world images as well as fabricating some images using a Text to Image model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e6d06-5c92-4eec-82cb-8ea0ecb52f23",
   "metadata": {},
   "source": [
    "### Installing required Libraries\n",
    "\n",
    "The following cells installs the necessary libraries to complete our data preparation. We are also installing a 3rd party library called FiftyOne which is an open-sourced tool for downloading free curated datasets utilised for various computer vision models. Notably the library provides us a programatic interface to query and download open datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e705e54-4ae6-44ba-9377-ec6bd9bb7c71",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install setuptools==70.1.1\n",
    "!pip install fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29381e-178e-4e3b-8fc0-e93c23041952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import json\n",
    "import pprint as pp\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import time\n",
    "import pprint\n",
    "import io\n",
    "import base64\n",
    "import uuid\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee697895-e51c-4af0-9e41-e80359f1c97c",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "For our exercise we are going to be utilising a small slice of images from the [Google Open Images dataset v7](https://storage.googleapis.com/openimages/web/index.html). The dataset contains labelled assets accross training, validation and test split. We will not be utilising any bounding boxes or class labels for our exercise but generally they can be utilised for traditional ML training purposes. \n",
    "\n",
    "For the purposes of this lab we are only interested in a select few classes from the validation set to keep the download to a minimum we are also applying a max_samples flag to 200 images only. The following cells utilises the FiftyOne library to download the dataset and save into disk for subseuqent labs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ad128e-8500-48ee-b814-379a10dcf813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# includes all the available classes in the dataset \n",
    "#classes = fo.utils.openimages.get_classes()\n",
    "\n",
    "fo.config.dataset_zoo_dir = \"./data/\" # set the location for the dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248e1c2-dc7f-499d-af95-e214a9d0196e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preselect some classes as desired\n",
    "# fiftyone downloads classes and hierarchy metadata but for our use case we will not be needing them.\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    split=\"validation\",\n",
    "    label_types=[\"points\"],\n",
    "    classes = [\"Baseball bat\", \"Baseball\"],\n",
    "    max_samples=100, # limit to 100 samples but can be increased as desired \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d266d25-019a-4454-84ef-a05243c65f1c",
   "metadata": {},
   "source": [
    "The following cell implements a simple helper function to display images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca9e49b-514c-4d0b-9f18-a09d379986fc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper functions for generating metadata and creating some previews\n",
    "\n",
    "def display_image(path):\n",
    "    im = Image.open(path)\n",
    "    plt.imshow(im)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303a21a3-62bb-499f-a955-148ea2b1bcf3",
   "metadata": {},
   "source": [
    "## Fabricate dataset using Titan \n",
    "\n",
    "Now that we have some images downloaded from the Open Images dataset, we are going to further augment our assets library with some fabricated images. The fabrication is necessary to generate enough similar images for a set topic so that we are able to conduct a semantic similarity search and ephasise the final results of the semantic search for lab purposes.\n",
    "\n",
    "The fabricated images are generated using [Amazon Titan Image Generator G1 model](https://docs.aws.amazon.com/bedrock/latest/userguide/titan-image-models.html). Amazon Titan Image Generator v1 enables users to generate and edit images in versatile ways. Users can create images that match their text-based descriptions by simply inputting natural language prompts. Furthermore, they can upload and edit existing images, including applying text-based prompts without the need for a mask, or editing specific parts of an image using an image mask. The model also supports outpainting, which extends the boundaries of an image, and inpainting, which fills in missing areas. \n",
    "\n",
    "A 2nd LLM, [Anthropic Claude Haiku](https://aws.amazon.com/bedrock/claude/) is utilised in tandem to generate the prompts required to create the images. Haiku is Anthropic's most compact and fastest model and provides the ideal balance of price performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a59649-5a50-4ca0-8075-55bcfd2b0a7f",
   "metadata": {},
   "source": [
    "The following cell contains helper function to generate an image using Titan Image Generator model as well as saving the output as image on disk. Since titan returns images in base64 we are required to decode before saving to file.\n",
    "\n",
    "In addition, we have a 2nd function defined in order to generate sufficient randomisation and variations in the generated images. This is done by calling Haiku to create a series of prompts and negative prompts which we can utilise to generate images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37e645-bb86-4eac-a905-175b92e1287b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a series images using titan image generator to augment the dataset with our fabricated images \n",
    "# we will leave a set for testing and search purposes later. \n",
    "# amazon.titan-image-generator-v1\n",
    "from botocore.exceptions import ClientError\n",
    "import logging\n",
    "\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')\n",
    "\n",
    "def generate_image(p, seed=1, number_of_images=5):\n",
    "\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    modelId = 'amazon.titan-image-generator-v2:0'\n",
    "    \n",
    "    #modelId=\"amazon.titan-image-generator-v1\",\n",
    "\n",
    "    response = None\n",
    "    try: \n",
    "        # something \n",
    "        # Create payload\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"taskType\": \"TEXT_IMAGE\",\n",
    "                \"textToImageParams\": {\n",
    "                    \"text\": p[\"prompt\"],                    # Required\n",
    "                    \"negativeText\": p[\"neg_prompt\"]   # Optional\n",
    "                },\n",
    "                \"imageGenerationConfig\": {\n",
    "                    \"numberOfImages\": number_of_images,   # Range: 1 to 5 \n",
    "                    #\"quality\": \"standard\",  # Options: standard or premium\n",
    "                    \"height\": 512,        # Supported height list in the docs \n",
    "                    \"width\": 512,         # Supported width list in the docs\n",
    "                    \"cfgScale\": 7.5,       # Range: 1.0 (exclusive) to 10.0\n",
    "                    \"seed\": seed             # Range: 0 to 214783647\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        # Make model request\n",
    "        response = boto3_bedrock.invoke_model(\n",
    "            body=body,\n",
    "            modelId=modelId,\n",
    "            accept=\"application/json\", \n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "    except ClientError as err:\n",
    "        # error state \n",
    "        message = err.response[\"Error\"][\"Message\"]\n",
    "        logger.error(\"A client error occurred: %s\", message)\n",
    "        # use a default prompt to generate image \n",
    "        defaultprompt = {\n",
    "            \"prompt\": \"person playing baseball swinging bat to score a home run\",\n",
    "            \"neg_prompt\": \"blurry image\"\n",
    "        }\n",
    "        # Create payload\n",
    "        body = json.dumps(\n",
    "            {\n",
    "                \"taskType\": \"TEXT_IMAGE\",\n",
    "                \"textToImageParams\": {\n",
    "                    \"text\": defaultprompt[\"prompt\"],                    # Required\n",
    "                    \"negativeText\": defaultprompt[\"neg_prompt\"]   # Optional\n",
    "                },\n",
    "                \"imageGenerationConfig\": {\n",
    "                    \"numberOfImages\": number_of_images,   # Range: 1 to 5 \n",
    "                    #\"quality\": \"standard\",  # Options: standard or premium\n",
    "                    \"height\": 512,        # Supported height list in the docs \n",
    "                    \"width\": 512,         # Supported width list in the docs\n",
    "                    \"cfgScale\": 7.5,       # Range: 1.0 (exclusive) to 10.0\n",
    "                    \"seed\": seed             # Range: 0 to 214783647\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        # Make model request\n",
    "        response = boto3_bedrock.invoke_model(\n",
    "            body=body,\n",
    "            modelId=modelId,\n",
    "            accept=\"application/json\", \n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "\n",
    "    # Process the image payload\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    # img1_b64 = response_body[\"images\"][0] # in bytes IO\n",
    "    images_b64 = response_body[\"images\"]\n",
    "    images = []\n",
    "    \n",
    "    # save to disk \n",
    "    os.makedirs(\"./data/titan\", exist_ok=True)\n",
    "\n",
    "    for img_b64 in images_b64:\n",
    "        # Decode + save\n",
    "        filename = uuid.uuid4()\n",
    "        img = Image.open(\n",
    "            io.BytesIO(\n",
    "                base64.decodebytes(\n",
    "                    bytes(img_b64, \"utf-8\")\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        img.save(\"data/titan/{0}.png\".format(filename))\n",
    "        images.append(img)\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def generate_image_prompts(messages, max_tokens,top_p,temp):\n",
    "\n",
    "    model_id = \"anthropic.claude-3-haiku-20240307-v1:0\" # calling haiku \n",
    "    body=json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": temp,\n",
    "            \"top_p\": top_p\n",
    "        }  \n",
    "    )  \n",
    "    \n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=model_id)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text = response_body[\"content\"][0][\"text\"]    \n",
    "\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705c1ac-f060-44d0-b4ee-34f5c222e41f",
   "metadata": {},
   "source": [
    "### Utilising LLM to create image generation prompts \n",
    "\n",
    "In the following cell we are defining a prompt template, instructing the LLM to generate 20 prompts for a given topic as well as providing some guidance on how to output the prompt as JSON array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2065c17c-78f9-42cd-b1a9-6325518e528b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbda214-ef10-4977-85e0-2c59460a87f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first let us create a series of prompts and negative prompts using Bedrock Claude \n",
    "prompt = \"\"\"\n",
    "You are an image prompt generator. Based on the specified comma separated list of topics in the <topics> xml tags, generate a set of text prompts that can be used to generate images using a text to image generative model. \n",
    "Each prompt should only be about one topic and must be scoped to sports, or a sporting action. \n",
    "Make necessary determination on related subjects and themes based on the topic and be creative with the generated prompts. \n",
    "The output should contain a list of prompts as well as corresponding negative prompts as outlined in the <example_output> xml tags. \n",
    "All generated output need to follow responsible use of AI practices and all prompts need to avoid questionable, adult, and explicit terms at all times. \n",
    "Generate 20 prompts\n",
    "\n",
    "<topics>{topic}</topics>\n",
    "\n",
    "\n",
    "The generated prompts will be directly passed to an text to image model so ensure the prompts contain enough details and creative descriptions. \n",
    "\n",
    "Output the data as well formed json array only as outlined in the <example_output> XML tags without any newline characters in the output\n",
    "\n",
    "<example_output> \n",
    "[\n",
    "    { \"prompt\":\"person playing baseball swinging bat to score a home run\", \"neg_prompt\"=\"blurry image\" },\n",
    "    { \"prompt\":\"person playing baseball at a packed stadium with cheering fans\", \"neg_prompt\"=\"video game graphics\" },\n",
    "    { \"prompt\":\"baseball player sliding to make a home run, electric atmosphere\", \"neg_prompt\"=\"do not include baseball bats\" },\n",
    "]\n",
    "</example_output> \n",
    "\n",
    "output: \n",
    "\n",
    "[\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d7e3a9-1cc8-4748-bd35-8c0888eef6c3",
   "metadata": {},
   "source": [
    "Execute the prompt generate some prompts to be used for image generation. The topics are supplied via the placeholder \"topic\" parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff3757-3733-432b-88f9-5cb90498edf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_prompts = []\n",
    "request_payload = [\n",
    "        { \"role\": \"user\",\n",
    "          \"content\": [\n",
    "              {\"type\": \"text\",\"text\": prompt.replace(\"{topic}\",\"baseball, soccer, basketball\")}\n",
    "          ]\n",
    "        }\n",
    "    ]\n",
    "response = generate_image_prompts(messages=request_payload,max_tokens=4096,temp=0.5,top_p=0.9) \n",
    "image_prompts = json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9becf0-606f-4048-a74e-ce7567b7c33e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lets review the prompts that we have prepared \n",
    "pprint.pp(image_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930146e6-f85e-4b24-bb28-eb97320bab7d",
   "metadata": {},
   "source": [
    "### Generating the images \n",
    "\n",
    "Now that we have a series of prompts automatically generated using Claude we are now ready to create some images. \n",
    "\n",
    "The following cell invokes the generate_image helper function for each image prompts. In order to complete the task faster we have opted to run this accross 5 threads. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b2c2b-b091-4189-8bdc-df9494aba368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate series of images using the prompts prepared, we are going to create 5 images per prompt\n",
    "# approx 30 seconds per set of 5 images - approx 2 mins \n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "pool = ThreadPool(5)\n",
    "\n",
    "start_time = time.time()\n",
    "results = pool.map(generate_image, image_prompts)\n",
    "duration = time.time() - start_time\n",
    "print(f\"Processed {len(image_prompts)} in {duration} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c720faa0-7d0a-4c10-8772-527cdbfd70f7",
   "metadata": {},
   "source": [
    "Let us preview a sample image before proceeding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341f9362-39c1-4ebb-8568-4119250eb80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display a sample image from the fabricated set\n",
    "results[random.randrange(0,20)][random.randrange(0,4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff0d1e-fa01-4fbf-8a1b-093e68187fc3",
   "metadata": {},
   "source": [
    "## Combining a curated dataset of open image and fabricated images \n",
    "\n",
    "The final step of the data preparation is simply to combine the sample 200 images downloaded from the Open Images dataset and the fabricated images generated using Titan and Haiku. In order to improve ease of access in subsequent notebooks, we are going to be creating a dataframe with various metadata attributes (e.g keywords, description) which we will populate in data enrichment notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028555d-2dd2-4b38-ad88-4bc2f5d335f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# move all images into curated folder \n",
    "os.makedirs(\"data/curated-images\", exist_ok=True)\n",
    "\n",
    "!cp -a ./data/open-images-v7/validation/data/. ./data/curated-images/\n",
    "!cp -a ./data/titan/. ./data/curated-images/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40a76c-9e77-4f54-be6a-281758534b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# resize and reduce quality of all images to make inferences faster (e.g. titan has a 5MB limit per image) \n",
    "\n",
    "from PIL import Image\n",
    "import os, sys\n",
    "\n",
    "path = \"./data/curated-images/\"\n",
    "resized_path = \".data/resized-images/\"\n",
    "# create resized images folder\n",
    "os.makedirs(\"data/resized-images\", exist_ok=True)\n",
    "\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "def resize():\n",
    "    for item in dirs:\n",
    "        if os.path.isfile(path+item):\n",
    "            im = Image.open(path+item)\n",
    "            f, e = os.path.splitext(path+item)\n",
    "            imResize = im.resize((200,200), Image.Resampling.LANCZOS)\n",
    "            imResize.save(f.replace(\"curated-images\",\"resized-images\") + \".jpg\", 'JPEG', quality=90)\n",
    "\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc5624e-8f09-4e6c-86c8-b0b3581fbbab",
   "metadata": {},
   "source": [
    "The following cell creates the dataframe with empty title, descrption, keywords and other metadata fields. We are going to utilise the file name as image_id attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd57630-0956-4da8-a24c-7e892a8e03d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load all the images into a single dataset\n",
    "\n",
    "sample_images = []\n",
    "images_dir = \"./data/resized-images\"\n",
    "\n",
    "for filename in os.listdir(images_dir):\n",
    "    f = os.path.join(images_dir, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        sample_images.append(\n",
    "            {\n",
    "                'image_id':filename,\n",
    "                'path':f,\n",
    "                'title':'',\n",
    "                'description':'',\n",
    "                'tags':[],\n",
    "                'keywords':[],\n",
    "                'embeddings':[]\n",
    "            }\n",
    "        )\n",
    "\n",
    "df_images = pd.DataFrame(sample_images)\n",
    "\n",
    "df_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1c7a4-1098-4592-87b7-24693ffe8412",
   "metadata": {},
   "source": [
    "Display image from the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf61d9f-3423-45e6-a689-b7e0cdeccf6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image_path = df_images.sample()[\"path\"].values[0]\n",
    "display_image(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff0298-6f62-4683-a7ec-b4b881608571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fabricated_images = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773f8d0-ebc8-4658-a6bb-297ac04ca83e",
   "metadata": {},
   "source": [
    "Save the dataframe for use in subsequent notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964fce60-e43c-422b-bc04-d7df58bc1d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save for use in next notebook \n",
    "%store df_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6609b479-e5cd-4d1e-ac18-d2583fce3ee0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dda471c-99ca-4bc1-9d02-66e4b73418fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment below line to delete the dataset\n",
    "#foz.delete_zoo_dataset(\"open-images-v7\", split=\"validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
